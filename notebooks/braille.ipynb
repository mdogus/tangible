{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Python Projects\\tangible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Set the path as tangible\n",
    "os.chdir('..')\n",
    "\n",
    "# Check current path \n",
    "print(os.getcwd())\n",
    "# Visualization\n",
    "from src.visualization import plot_categorical_distribution, plot_numerical_distribution, plot_crosstab, plot_scatter, plot_frequency_bar, plot_frequency_heatmap, create_frequency_bar_tangible, create_table, create_striped_table, plot_box_high_contrast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file\n",
    "file_path = 'data/contractions/turkce_6.txt'\n",
    "base_name = os.path.basename(file_path)\n",
    "document_name = os.path.splitext(base_name)[0]\n",
    "print(\"Document: \" + document_name)\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metin Temizleme ve Tokenizasyon\n",
    "# 1) Küçük harfe dönüştür\n",
    "text = text.lower()\n",
    "\n",
    "# 2) Noktalama işaretlerini sil (regex ile)\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# 3) Sayı vb. temizle\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Tokenization\n",
    "tokens = text.split()  # Boşluk karakterine göre ayırır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Türkçe sözlük dosyası kullanarak metin temizliği yap (tr_isim_sifat.csv)\n",
    "# Türkçe sözlüğü yükle\n",
    "turkish_dict_path = 'data/contractions/tr_isim_sifat.csv'\n",
    "df_turkish_dict = pd.read_csv(turkish_dict_path)\n",
    "\n",
    "# 1) form2 sütunundaki boş hücreleri \"\" ile doldur\n",
    "df_turkish_dict['form2'] = df_turkish_dict['form2'].fillna(\"\")\n",
    "\n",
    "# 2) Sadece küçük harfe dönüştürerek kelimeleri kümeye ekle\n",
    "turkish_words = set()\n",
    "\"\"\"\n",
    "for col in ['form1', 'form2']:\n",
    "    # Küçük harfe dönüştür ve kümeye ekle\n",
    "    turkish_words.update(df_turkish_dict[col].str.lower().tolist())\n",
    "\"\"\"\n",
    "for col in ['form1', 'form2']:\n",
    "    # Küçük harfe dönüştür, regex ile özel karakterleri temizle ve kümeye ekle\n",
    "    turkish_words.update(\n",
    "        df_turkish_dict[col]\n",
    "        .str.lower()  # Küçük harfe dönüştür\n",
    "        .str.replace(r'[^a-zâçğıöşü\\s]', '', regex=True)  # Sadece harf ve boşlukları bırak\n",
    "        .dropna()  # Boş değerleri çıkar\n",
    "        .tolist()  # Listeye dönüştür\n",
    "    )\n",
    "\n",
    "# Boş değerleri kümeden çıkar (eğer varsa)\n",
    "turkish_words.discard(\"\")\n",
    "df_turkish_words = pd.DataFrame(list(turkish_words), columns=['word'])\n",
    "df_turkish_words = df_turkish_words.sort_values('word', ascending=True)\n",
    "print(df_turkish_words[df_turkish_words['word'].str.startswith('glâ')])\n",
    "print(df_turkish_words)\n",
    "# İlk 10 kelimeyi yazdır\n",
    "\n",
    "#print(\"Türkçe sözlükteki ilk 10 kelime:\", list(turkish_words)[:10])\n",
    "#print(df_turkish_words)\n",
    "\n",
    "# -- Metni temizleme ve tokenize etme --\n",
    "text_path = 'data/contractions/sayi_11.txt'\n",
    "with open(text_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 1) Küçük harfe dönüştür\n",
    "text = text.lower()\n",
    "\n",
    "# 2) Noktalama işaretlerini sil\n",
    "text = re.sub(r'[^\\w\\sâçğıöşü]', '', text)\n",
    "\n",
    "# 3) Sayıları temizle\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# 4) Tokenizasyon\n",
    "tokens = text.split()  # Boşluklara göre sözcükleri ayır\n",
    "\n",
    "# 5) Türkçe sözlükte olmayan sözcükleri çıkar\n",
    "filtered_tokens = [word for word in tokens if word in turkish_words]\n",
    "\n",
    "# Sonuçları birleştir\n",
    "#cleaned_text = ' '.join(filtered_tokens)\n",
    "df_cleaned_text = pd.DataFrame(list(filtered_tokens), columns=['word'])\n",
    "df_cleaned_text['count'] = 1\n",
    "df_cleaned_text_word_counts = df_cleaned_text.groupby('word')['count'].sum().reset_index()\n",
    "df_cleaned_text_word_counts = df_cleaned_text_word_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Temizlenmiş metni yazdır\n",
    "#print(\"Temizlenmiş metin:\", cleaned_text)\n",
    "print(df_cleaned_text_word_counts)\n",
    "print(df_cleaned_text_word_counts[df_cleaned_text_word_counts['word'].str.startswith('daha')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame and Save to CSV file\n",
    "df = pd.DataFrame(tokens, columns=['word'])\n",
    "#df = pd.DataFrame(filtered_tokens, columns=['word'])\n",
    "df['count'] = 1\n",
    "\n",
    "# Gruplayarak frekans (count) değerini hesapla\n",
    "word_counts = df.groupby('word')['count'].sum().reset_index()\n",
    "\n",
    "# Dosya ismini ekle\n",
    "#word_counts['source'] = document_name\n",
    "\n",
    "# Frekansına göre büyükten küçüğe sırala\n",
    "\n",
    "word_counts = word_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# İlk 20 kelimeyi görüntüleyelim\n",
    "print(word_counts)\n",
    "print(word_counts[word_counts['word'].str.startswith('daha')])\n",
    "\n",
    "# CSV dosyasına kaydet\n",
    "\"\"\"csv_path = 'data/contractions/word_frequencies_textbooks.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    # CSV yoksa oluştur (header dahil)\n",
    "    word_counts.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "else:\n",
    "    # CSV varsa oku ve birleştir (append)\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    combined_df = pd.concat([existing_df, word_counts], ignore_index=True)\n",
    "    combined_df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hunspell Türkçe sözlüğü kullanarak metni temizle\n",
    "turkish_dict_path = 'data/contractions/hunspell_tr.csv'\n",
    "df_turkish_dict = pd.read_csv(turkish_dict_path, header=None, names=[\"word\"])\n",
    "\n",
    "# 1) Boş değerleri çıkar ve küçük harfe dönüştür\n",
    "df_turkish_dict['word'] = df_turkish_dict['word'].str.strip().str.lower()\n",
    "df_turkish_dict = df_turkish_dict.dropna()  # Boş satırları sil\n",
    "\n",
    "# 2) Kelimeleri kümeye ekle\n",
    "turkish_words = set(df_turkish_dict['word'].tolist())\n",
    "\n",
    "# Boş değerleri kümeden çıkar (eğer varsa)\n",
    "turkish_words.discard(\"\")  # Herhangi bir boş kelime varsa çıkar\n",
    "\n",
    "# 3) Sözlüğü DataFrame olarak sıralayıp inceleyin\n",
    "df_turkish_words = pd.DataFrame(list(turkish_words), columns=['word'])\n",
    "df_turkish_words = df_turkish_words.sort_values('word', ascending=True)\n",
    "\n",
    "# Sözlükte \"kâ\" ile başlayan kelimeleri yazdır\n",
    "#print(df_turkish_words[df_turkish_words['word'].str.startswith('kâ')])\n",
    "\n",
    "# Tüm sözlüğü yazdır\n",
    "#print(df_turkish_words)\n",
    "\n",
    "# -- Metni temizleme ve tokenize etme --\n",
    "text_path = 'data/contractions/turkce_6.txt'\n",
    "with open(text_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "base_name = os.path.basename(text_path)\n",
    "document_name = os.path.splitext(base_name)[0]\n",
    "\n",
    "# 1) Küçük harfe dönüştür\n",
    "text = text.lower()\n",
    "\n",
    "# 2) Noktalama işaretlerini sil\n",
    "text = re.sub(r'[^\\w\\sçğıöşü]', '', text)\n",
    "\n",
    "# 3) Sayıları temizle\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# 4) Tokenizasyon\n",
    "tokens = text.split()  # Boşluklara göre sözcükleri ayır\n",
    "\n",
    "# 5) Sözlükteki kelimelerle başlayan sözcükleri kontrol et\n",
    "def is_valid_word(word, dictionary):\n",
    "    # Kelimenin sözlükteki herhangi bir kelimeyle başlayıp başlamadığını kontrol et\n",
    "    for valid_word in dictionary:\n",
    "        if word.startswith(valid_word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_tokens = [word for word in tokens if is_valid_word(word, turkish_words)]\n",
    "\n",
    "# Sonuçları birleştir\n",
    "df_tokens = pd.DataFrame(list(filtered_tokens), columns=['word'])\n",
    "df_tokens['count'] = 1\n",
    "df_tokens = df_tokens.groupby('word')['count'].sum().reset_index()\n",
    "df_tokens = df_tokens.sort_values('count', ascending=False)\n",
    "df_tokens['source'] = document_name\n",
    "df_tokens = df_tokens[['word', 'count', 'source']]\n",
    "\n",
    "# Temizlenmiş metni yazdır\n",
    "print(df_tokens)\n",
    "print(df_tokens[df_tokens['word'].str.startswith('daha')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Hunspell) CSV dosyasına kaydet\n",
    "csv_path = 'data/contractions/word_frequencies_textbooks.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    # CSV yoksa oluştur (header dahil)\n",
    "    df_text_word_counts.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"CSV dosyası oluşturuldu: {csv_path}\")\n",
    "else:\n",
    "    # CSV dosyası varsa birleştir (append)\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    combined_df = pd.concat([existing_df, df_text_word_counts], ignore_index=True)\n",
    "    combined_df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"CSV dosyasına eklendi: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tekrar eden sözcükleri birleştir (Word Frequencies CSV dosyası için)\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sözcük bazında topla\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "df_merged = df_merged.sort_values('count', ascending=False)\n",
    "\n",
    "# Eğer 'source' (belge adı) sütunu da varsa ve hem 'word' hem de 'source' bazında birleştirmek istiyorsanız:\n",
    "# df_merged = df.groupby(['word', 'source'], as_index=False)['count'].sum()\n",
    "# Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val = df_merged['count'].mean()\n",
    "std_val = df_merged['count'].std()\n",
    "\n",
    "# Standart sapmanın 0 olması ihtimaline karşı kontrol et\n",
    "if std_val == 0:\n",
    "    # Böyle bir durumda tüm z-skorları 0 yapılabilir\n",
    "    df_merged['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekle\n",
    "    df_merged['z_score'] = (df_merged['count'] - mean_val) / std_val\n",
    "\n",
    "# Sonucu incele\n",
    "print(mean_val)\n",
    "print(std_val)\n",
    "print(df_merged)\n",
    "\n",
    "# CSV olarak kaydet\n",
    "#df_merged.to_csv('data/contractions/word_frequencies_merged.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "import nltk\n",
    "\n",
    "# Türkçe stopword'leri indirelim (bir kereye mahsus)\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK'nin Türkçe stopword'lerini alalım (tamamen yeterli olmayabilir, isteğe göre genişletilebilir)\n",
    "#turkish_stopwords_nltk = stopwords.words('turkish')\n",
    "turkish_stopwords_nltk = []\n",
    "print(turkish_stopwords_nltk)\n",
    "# Ek olarak kendi özel stopword listenizi de tanımlayabilirsiniz\n",
    "csv_path_stopwords = 'data/contractions/stopwords.csv'\n",
    "df_my_stopwords = pd.read_csv(csv_path_stopwords, header=None)\n",
    "my_stopwords = df_my_stopwords[0].tolist()\n",
    "# İki listeyi birleştirelim\n",
    "\n",
    "turkish_stopwords = set(turkish_stopwords_nltk + my_stopwords)\n",
    "\n",
    "# --- Asıl analiz ---\n",
    "\n",
    "# 1) CSV'yi okuyalım\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Sözcük bazında topla (aynı 'word' birden çok satırda olabilir diye)\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "\n",
    "# 3) Stopword’leri çıkaralım\n",
    "df_stopwords_removed = df_merged[~df_merged['word'].isin(turkish_stopwords)]\n",
    "\n",
    "# 4) Temizlenmiş veriyi frekansa göre sırala\n",
    "df_stopwords_removed = df_stopwords_removed.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "#df_stopwords_removed = df_stopwords_removed.sort_values('word', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 5) Ortalamayı ve standart sapmayı hesaplayalım\n",
    "mean_val_sw = df_stopwords_removed['count'].mean()\n",
    "std_val_sw = df_stopwords_removed['count'].std()\n",
    "\n",
    "# 6) Z-skorunu hesapla\n",
    "if std_val_sw == 0:\n",
    "    df_stopwords_removed['z_score'] = 0\n",
    "else:\n",
    "    df_stopwords_removed['z_score'] = (df_stopwords_removed['count'] - mean_val_sw) / std_val_sw\n",
    "\n",
    "# 7) Sonucu görelim\n",
    "print(mean_val_sw)\n",
    "print(std_val_sw)\n",
    "print(df_stopwords_removed.head(20))\n",
    "\n",
    "# 8) İsterseniz CSV olarak kaydedebilirsiniz\n",
    "# df_stopwords_removed.to_csv('data/contractions/word_frequencies_merged_no_stopwords.csv', \n",
    "#                             index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies_textbooks.csv'\n",
    "df_single = pd.read_csv(csv_path)\n",
    "\n",
    "# Tek harfli kısaltmalar listesi\n",
    "csv_path_con_single = 'data/contractions/con_single.csv'\n",
    "df_con_single = pd.read_csv(csv_path_con_single, header=None)\n",
    "contractions_list_single = df_con_single[0].tolist()\n",
    "print(f\"Bir Harfli Kısaltma sayısı: {df_con_single.size}\")\n",
    "\n",
    "# Stopwordleri çıkar\n",
    "csv_path_stopwords_single = 'data/contractions/stopwords_single.csv'\n",
    "df_my_stopwords_single = pd.read_csv(csv_path_stopwords_single, header=None)\n",
    "my_stopwords_single = df_my_stopwords_single[0].tolist()\n",
    "df_single = df_single[~df_single['word'].isin(my_stopwords_single)]\n",
    "print(f\"Toplam sözcük (Tüm kaynaklar): {df_single['count'].sum()}\")\n",
    "\n",
    "# 1) Listedeki sözcüklerle BAŞLAYAN tüm sözcüklerin toplam frekansını hesapla\n",
    "results = []\n",
    "for cword in contractions_list_single:\n",
    "    sub_count = df_single[df_single['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "\n",
    "    # Ünsüz yumuşamasına uğramış sözcükler varsa\n",
    "    if cword == \"büyük\":\n",
    "        sub_count += df_single[df_single['word'].str.startswith(\"büyüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"artık\":\n",
    "        sub_count += df_single[df_single['word'].str.startswith(\"artığ\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_single_freq = pd.DataFrame(results)\n",
    "print(f\"Toplam frekans (BHK): {df_single_freq['count'].sum()}\")\n",
    "print(f\"Yüzde (%): {df_single_freq['count'].sum() / df_single['count'].sum() * 100} \\n\")\n",
    "\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_single = df_single_freq['count'].mean()\n",
    "std_val_single = df_single_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_single == 0:\n",
    "    # z-skorlarını 0 yap\n",
    "    df_single_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekle\n",
    "    df_single_freq['z_score'] = (df_single_freq['count'] - mean_val_single) / std_val_single\n",
    "\n",
    "# 4) Dönüşüm Uygula\n",
    "# Log-Transfer uygula\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_single_freq['log_count'] = np.log1p(df_single_freq['count'])  # log(count + 1)\n",
    "# Box-Cox Dönüşümü\n",
    "# df_single_freq['count'] içinde sıfır veya çok küçük değerler varsa:\n",
    "df_single_freq['count_shifted'] = df_single_freq['count'] + 1\n",
    "# boxcox fonksiyonu iki değer döndürür: \n",
    "# 1. dönüşmüş veriler (transformed), 2. bulduğu en uygun lambda değeri (fitted_lambda)\n",
    "transformed_values, fitted_lambda = boxcox(df_single_freq['count_shifted'])\n",
    "df_single_freq['boxcox_count'] = transformed_values\n",
    "\n",
    "#print(\"Box-Cox için bulunan en uygun lambda değeri:\", fitted_lambda)\n",
    "\n",
    "# 5) Dönüşüm Sonrası Ortalama ve Standart Sapma Hesapla\n",
    "# Log değerlerin ortalama ve STD'sini al\n",
    "mean_log = df_single_freq['log_count'].mean()\n",
    "std_log = df_single_freq['log_count'].std()\n",
    "# Box-Cox değerlerinin ortalama ve STD'sini al\n",
    "mean_boxcox = df_single_freq['boxcox_count'].mean()\n",
    "std_boxcox = df_single_freq['boxcox_count'].std()\n",
    "\n",
    "# 6) Dönüşüm Sonrası Z-Skoru Hesapla\n",
    "# Log değer üzerinden z-skoru\n",
    "if std_log == 0:\n",
    "    df_single_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_single_freq['z_score_log'] = (df_single_freq['log_count'] - mean_log) / std_log\n",
    "# Box-Cox değer üzerinden z-skoru\n",
    "if std_boxcox == 0:\n",
    "    df_single_freq['z_score_boxcox'] = 0\n",
    "else:\n",
    "    df_single_freq['z_score_boxcox'] = (df_single_freq['boxcox_count'] - mean_boxcox) / std_boxcox\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları\n",
    "bins = [-np.inf, -1.5, -0.5, 0.5, 1.5, np.inf]\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta\", \"yüksek\", \"çok yüksek\"]\n",
    "df_single_freq['z_categories'] = pd.cut(df_single_freq['z_score_boxcox'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_single = df_single_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_single_freq['percentage'] = (df_single_freq['count'] / total_count_single) * 100\n",
    "df_single_percent = df_single_freq[['word', 'count', 'percentage', 'z_score_boxcox', 'z_score', 'z_categories']]\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_single_freq = df_single_freq.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "df_single_percent = df_single_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(f\"Ortalama: {mean_val_single}\")\n",
    "print(f\"Standart sapma: {std_val_single} \\n\")\n",
    "print(f\"Skewness (Raw Data): {df_single_percent['count'].skew()}\")\n",
    "print(f\"Skewness (Log-Transfer): {df_single_freq['log_count'].skew()}\")\n",
    "print(f\"Skewness (Box-Cox): {df_single_freq['boxcox_count'].skew()} \\n\")\n",
    "# Histogram ve Boxplot\n",
    "#df_single_percent['count'].hist()\n",
    "#plt.show()\n",
    "#plot_box_high_contrast(df_single_percent)\n",
    "#plot_box_high_contrast(df_single_freq, column='log_count')\n",
    "#plot_box_high_contrast(df_single_freq, column='boxcox_count')\n",
    "# Filtreleme yap\n",
    "\n",
    "print(df_single_percent[df_single_percent['z_categories'] == 'çok yüksek'])\n",
    "print(df_single_percent[df_single_percent['z_categories'] == 'çok düşük'])\n",
    "#print(df_single_percent[df_single_percent['word'] == 'büyük'])\n",
    "#TODO: Yeo-Johnson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İki Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# İki harfli kısaltmalar listesi\n",
    "csv_path_con_double = 'data/contractions/con_double.csv'\n",
    "df_con_double = pd.read_csv(csv_path_con_double, header=None)\n",
    "# 2. sütundaki değerleri listeye al\n",
    "contractions_double = df_con_double[1].tolist()\n",
    "print(contractions_double)\n",
    "\n",
    "# 1) Listedeki her sözcükle BAŞLAYAN tüm sözcüklerin toplam frekansını bulalım\n",
    "results = []\n",
    "for cword in contractions_double:\n",
    "    sub_count = df[df['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "    # Ünsüz yumuşaması varsa frekansa ekle\n",
    "    if cword == \"cevap\":\n",
    "        sub_count += df[df['word'].str.startswith(\"cevab\", na=False)]['count'].sum()\n",
    "    elif cword == \"çeşit\":\n",
    "        sub_count += df[df['word'].str.startswith(\"çeşid\", na=False)]['count'].sum()\n",
    "    elif cword == \"çocuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"çocuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"kitap\":\n",
    "        sub_count += df[df['word'].str.startswith(\"kitab\", na=False)]['count'].sum()\n",
    "    elif cword == \"küçük\":\n",
    "        sub_count += df[df['word'].str.startswith(\"küçüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"sebep\":\n",
    "        sub_count += df[df['word'].str.startswith(\"sebeb\", na=False)]['count'].sum()\n",
    "    elif cword == \"sıcak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"sıcağ\", na=False)]['count'].sum()\n",
    "    elif cword == \"soğuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"soğuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"toprak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"toprağ\", na=False)]['count'].sum()\n",
    "    # Ünlü düşmesi varsa frekansa ekle\n",
    "    elif cword == \"cisim\":\n",
    "        sub_count += df[df['word'].str.startswith(\"cism\", na=False)]['count'].sum()\n",
    "    elif cword == \"kısım\":\n",
    "        sub_count += df[df['word'].str.startswith(\"kısm\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_double_freq = pd.DataFrame(results)\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_double = df_double_freq['count'].mean()\n",
    "std_val_double = df_double_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_double == 0:\n",
    "    df_double_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekleyelim\n",
    "\n",
    "    df_double_freq['z_score'] = (df_double_freq['count'] - mean_val_double) / std_val_double\n",
    "\n",
    "# 4) Log-Transfer uygula\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_double_freq['log_count'] = np.log1p(df_double_freq['count'])  # log(count + 1)\n",
    "\n",
    "# 5) Log değerlerin ortalamasını ve std'sini alın\n",
    "mean_double_log = df_double_freq['log_count'].mean()\n",
    "std_double_log = df_double_freq['log_count'].std()\n",
    "\n",
    "# 6) Log değer üzerinden z-skoru\n",
    "if std_double_log == 0:\n",
    "    df_double_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_double_freq['z_score_log'] = (df_double_freq['log_count'] - mean_double_log) / std_double_log\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları (soldan sağa sıralı):\n",
    "bins = [-np.inf, -1, -0.5, 0, 0.5, 1, np.inf]\n",
    "# Bu aralıklara denk gelen etiketler (labels):\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta düşük\", \"orta yüksek\", \"yüksek\", \"çok yüksek\"]\n",
    "df_double_freq['z_categories'] = pd.cut(df_double_freq['z_score_log'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_double = df_double_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_double_freq['percentage'] = (df_double_freq['count'] / total_count_double) * 100\n",
    "df_double_percent = df_double_freq[['word', 'count', 'percentage', 'z_score_log', 'z_categories']]\n",
    "\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_double_percent = df_double_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(mean_val_double)\n",
    "print(std_val_double)\n",
    "#print(df_double_percent)\n",
    "# Çok düşük olanları sırala\n",
    "print(df_double_percent[df_double_percent['z_categories'] == 'çok yüksek'])\n",
    "#print(df_double_percent[df_double_percent['word'] == 'küçük'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
