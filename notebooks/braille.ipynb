{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\Documents\\Python Projects\\tangible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set the path as tangible\n",
    "os.chdir('..')\n",
    "\n",
    "# Check current path \n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 102-Ahmet Ümit _ İstanbul Hatırası\n"
     ]
    }
   ],
   "source": [
    "# Read the text file\n",
    "file_path = 'data/contractions/102-Ahmet Ümit _ İstanbul Hatırası.txt'\n",
    "base_name = os.path.basename(file_path)\n",
    "document_name = os.path.splitext(base_name)[0]\n",
    "print(\"Document: \" + document_name)\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Küçük harfe dönüştür\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 2) Noktalama işaretlerini sil (regex ile)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#    Burada ^\\w\\s -> Alfanumerik karakterler ve boşluklar dışındaki her şeyi temizleyecek.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Küçük harfe dönüştür\n",
    "text = text.lower()\n",
    "\n",
    "# 2) Noktalama işaretlerini sil (regex ile)\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# 3) Sayı vb. temizle\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Tokenization\n",
    "tokens = text.split()  # Boşluk karakterine göre ayırır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create data frame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtokens\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Gruplayarak frekans (count) değerini hesapla\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# Create data frame\n",
    "df = pd.DataFrame(tokens, columns=['word'])\n",
    "df['count'] = 1\n",
    "\n",
    "# Gruplayarak frekans (count) değerini hesapla\n",
    "word_counts = df.groupby('word')['count'].sum().reset_index()\n",
    "# Dosya ismini ekle\n",
    "word_counts['source'] = document_name\n",
    "\n",
    "# Frekansına göre büyükten küçüğe sırala\n",
    "word_counts = word_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# İlk 20 kelimeyi görüntüleyelim\n",
    "print(word_counts.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasına kaydet\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    # CSV yoksa oluştur (header dahil)\n",
    "    word_counts.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "else:\n",
    "    # CSV varsa oku ve birleştir (append)\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    combined_df = pd.concat([existing_df, word_counts], ignore_index=True)\n",
    "    combined_df.to_csv(csv_path, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.870993819594753\n",
      "43.793707573021614\n",
      "                    word  count     z_score\n",
      "4821                 bir   5659  129.108251\n",
      "5356                  bu   2932   66.839032\n",
      "31948                 ve   2425   55.262026\n",
      "7022                  de   2004   45.648773\n",
      "6669                  da   1519   34.574122\n",
      "...                  ...    ...         ...\n",
      "38324      şüphelenmemiş      1   -0.088392\n",
      "38323  şüpheleniyorsunuz      1   -0.088392\n",
      "38322  şüpheleniyorsanız      1   -0.088392\n",
      "38321            şüpheci      1   -0.088392\n",
      "15                 abdye      1   -0.088392\n",
      "\n",
      "[38347 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Tekrar eden sözcükleri birleştir\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sözcük bazında topla\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "df_merged = df_merged.sort_values('count', ascending=False)\n",
    "\n",
    "# Eğer 'source' (belge adı) sütunu da varsa ve hem 'word' hem de 'source' bazında birleştirmek istiyorsanız:\n",
    "# df_merged = df.groupby(['word', 'source'], as_index=False)['count'].sum()\n",
    "# Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val = df_merged['count'].mean()\n",
    "std_val = df_merged['count'].std()\n",
    "\n",
    "# Standart sapmanın 0 olması ihtimaline karşı kontrol et\n",
    "if std_val == 0:\n",
    "    # Böyle bir durumda tüm z-skorları 0 yapılabilir\n",
    "    df_merged['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekle\n",
    "    df_merged['z_score'] = (df_merged['count'] - mean_val) / std_val\n",
    "\n",
    "# Sonucu incele\n",
    "print(mean_val)\n",
    "print(std_val)\n",
    "print(df_merged)\n",
    "\n",
    "# CSV olarak kaydet\n",
    "#df_merged.to_csv('data/contractions/word_frequencies_merged.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "4.4000730441134275\n",
      "21.36408305210143\n",
      "     word  count    z_score\n",
      "0     ama   1335  62.282099\n",
      "1      ne   1234  57.554538\n",
      "2    için   1053  49.082375\n",
      "3    daha    970  45.197349\n",
      "4   kadar    751  34.946500\n",
      "5    diye    738  34.338002\n",
      "6     çok    601  27.925370\n",
      "7     her    573  26.614759\n",
      "8   sonra    556  25.819031\n",
      "9      en    503  23.338232\n",
      "10  değil    498  23.104194\n",
      "11    ben    497  23.057387\n",
      "12  bütün    494  22.916964\n",
      "13    iki    489  22.682927\n",
      "14     mi    485  22.495696\n",
      "15    hiç    473  21.934006\n",
      "16   bile    441  20.436165\n",
      "17   önce    437  20.248935\n",
      "18  büyük    421  19.500014\n",
      "19    ali    421  19.500014\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "import nltk\n",
    "\n",
    "# Türkçe stopword'leri indirelim (bir kereye mahsus)\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK'nin Türkçe stopword'lerini alalım (tamamen yeterli olmayabilir, isteğe göre genişletilebilir)\n",
    "#turkish_stopwords_nltk = stopwords.words('turkish')\n",
    "turkish_stopwords_nltk = []\n",
    "print(turkish_stopwords_nltk)\n",
    "# Ek olarak kendi özel stopword listenizi de tanımlayabilirsiniz\n",
    "csv_path_stopwords = 'data/contractions/stopwords.csv'\n",
    "df_my_stopwords = pd.read_csv(csv_path_stopwords, header=None)\n",
    "my_stopwords = df_my_stopwords[0].tolist()\n",
    "# İki listeyi birleştirelim\n",
    "turkish_stopwords = set(turkish_stopwords_nltk + my_stopwords)\n",
    "\n",
    "# --- Asıl analiz ---\n",
    "\n",
    "# 1) CSV'yi okuyalım\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Sözcük bazında topla (aynı 'word' birden çok satırda olabilir diye)\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "\n",
    "# 3) Stopword’leri çıkaralım\n",
    "df_stopwords_removed = df_merged[~df_merged['word'].isin(turkish_stopwords)]\n",
    "\n",
    "# 4) Temizlenmiş veriyi frekansa göre sırala\n",
    "df_stopwords_removed = df_stopwords_removed.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "#df_stopwords_removed = df_stopwords_removed.sort_values('word', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 5) Ortalamayı ve standart sapmayı hesaplayalım\n",
    "mean_val_sw = df_stopwords_removed['count'].mean()\n",
    "std_val_sw = df_stopwords_removed['count'].std()\n",
    "\n",
    "# 6) Z-skorunu hesapla\n",
    "if std_val_sw == 0:\n",
    "    df_stopwords_removed['z_score'] = 0\n",
    "else:\n",
    "    df_stopwords_removed['z_score'] = (df_stopwords_removed['count'] - mean_val_sw) / std_val_sw\n",
    "\n",
    "# 7) Sonucu görelim\n",
    "print(mean_val_sw)\n",
    "print(std_val_sw)\n",
    "print(df_stopwords_removed.head(20))\n",
    "\n",
    "# 8) İsterseniz CSV olarak kaydedebilirsiniz\n",
    "# df_stopwords_removed.to_csv('data/contractions/word_frequencies_merged_no_stopwords.csv', \n",
    "#                             index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444.2142857142857\n",
      "359.96227756508216\n",
      "       word  count  percentage  z_score_log z_categories\n",
      "0      için   1596   12.831645     1.351232   çok yüksek\n",
      "1      daha    976    7.846921     0.972813       yüksek\n",
      "2       var    945    7.597685     0.947982       yüksek\n",
      "3     kadar    797    6.407783     0.816963       yüksek\n",
      "4       her    765    6.150507     0.785446       yüksek\n",
      "5       yok    736    5.917350     0.755725       yüksek\n",
      "6       çok    637    5.121402     0.644640       yüksek\n",
      "7       gün    617    4.960605     0.620112       yüksek\n",
      "8       şey    613    4.928445     0.615112       yüksek\n",
      "9     sonra    609    4.896286     0.610078       yüksek\n",
      "10    zaman    554    4.454092     0.537312       yüksek\n",
      "11    büyük    469    3.770703     0.409296  orta yüksek\n",
      "12     öyle    379    3.047114     0.245604  orta yüksek\n",
      "13    artık    349    2.805917     0.182273  orta yüksek\n",
      "14     göre    331    2.661200     0.141614  orta yüksek\n",
      "15     ilgi    277    2.227046     0.004912  orta yüksek\n",
      "16    neden    262    2.106448    -0.037803   orta düşük\n",
      "17    fakat    243    1.953690    -0.095549   orta düşük\n",
      "18    dünya    236    1.897411    -0.117965   orta düşük\n",
      "19     aynı    232    1.865252    -0.131073   orta düşük\n",
      "20      can    211    1.696414    -0.203810   orta düşük\n",
      "21     para    162    1.302460    -0.406217   orta düşük\n",
      "22    taraf    149    1.197942    -0.470223   orta düşük\n",
      "23     eğer    122    0.980865    -0.623049        düşük\n",
      "24     kısa     80    0.643190    -0.944743        düşük\n",
      "25   meydan     72    0.578871    -1.024824    çok düşük\n",
      "26    uygun     17    0.136678    -2.103019    çok düşük\n",
      "27  ekonomi      2    0.016080    -3.482837    çok düşük\n"
     ]
    }
   ],
   "source": [
    "# Bir Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Tek harfli kısaltmalar listesi\n",
    "csv_path_cons_single = 'data/contractions/cons_single.csv'\n",
    "df_cons_single = pd.read_csv(csv_path_cons_single, header=None)\n",
    "contractions_single = df_cons_single[0].tolist()\n",
    "\n",
    "# 1) Listedeki sözcüklerle BAŞLAYAN tüm sözcüklerin toplam frekansını bulalım\n",
    "results = []\n",
    "for cword in contractions_single:\n",
    "    sub_count = df[df['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "\n",
    "    # Eğer 'büyük' ve 'artık' sözcüklerinin yumuşamış formları varsa frekansa ekle\n",
    "    if cword == \"büyük\":\n",
    "        sub_count += df[df['word'].str.startswith(\"büyüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"artık\":\n",
    "        sub_count += df[df['word'].str.startswith(\"artığ\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_single_freq = pd.DataFrame(results)\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_single = df_single_freq['count'].mean()\n",
    "std_val_single = df_single_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_single == 0:\n",
    "    # Böyle bir durumda tüm z-skorlarını 0 yap\n",
    "    df_single_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekleyelim\n",
    "    df_single_freq['z_score'] = (df_single_freq['count'] - mean_val_single) / std_val_single\n",
    "\n",
    "# 4) Log-Transfer uygula\n",
    "\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_single_freq['log_count'] = np.log1p(df_single_freq['count'])  # log(count + 1)\n",
    "\n",
    "# 5) Log değerlerin ortalamasını ve std'sini alın\n",
    "mean_log = df_single_freq['log_count'].mean()\n",
    "std_log = df_single_freq['log_count'].std()\n",
    "\n",
    "# 6) Log değer üzerinden z-skoru\n",
    "if std_log == 0:\n",
    "    df_single_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_single_freq['z_score_log'] = (df_single_freq['log_count'] - mean_log) / std_log\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları (soldan sağa sıralı):\n",
    "bins = [-np.inf, -1, -0.5, 0, 0.5, 1, np.inf]\n",
    "# Bu aralıklara denk gelen etiketler (labels):\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta düşük\", \"orta yüksek\", \"yüksek\", \"çok yüksek\"]\n",
    "df_single_freq['z_categories'] = pd.cut(df_single_freq['z_score_log'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_single = df_single_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_single_freq['percentage'] = (df_single_freq['count'] / total_count_single) * 100\n",
    "df_single_percent = df_single_freq[['word', 'count', 'percentage', 'z_score_log', 'z_categories']]\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_single_percent = df_single_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(mean_val_single)\n",
    "print(std_val_single)\n",
    "print(df_single_percent)\n",
    "# Çok düşük olanları sırala\n",
    "#print(df_single_freq[df_single_freq['z_categories'] == 'yüksek'])\n",
    "#print(df_single_percent[df_single_percent['word'] == 'büyük'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beden', 'bağımsız', 'bilgi', 'bundan', 'beraber', 'basit', 'başka', 'bütün', 'böyle', 'bazı', 'cumhuriyet', 'cisim', 'cevap', 'çocuk', 'çoğu', 'çalışkan', 'çünkü', 'çeşit', 'çevre', 'değil', 'dolayı', 'demek', 'deney', 'devlet', 'fazla', 'gibi', 'gece', 'genel', 'güzel', 'haber', 'hiç', 'halk', 'hemen', 'hangi', 'hepsi', 'hayat', 'hazır', 'kabul', 'küçük', 'kadın', 'kahraman', 'kolay', 'kendi', 'kısım', 'kitap', 'kuvvet', 'kuzey', 'lazım', 'madde', 'millet', 'memleket', 'ancak', 'niçin', 'anadolu', 'nehir', 'anne', 'insan', 'arka', 'örneğin', 'arası', 'orta', 'sebep', 'sıcak', 'soğuk', 'eski', 'osmanlı', 'soru', 'savaş', 'aşağı', 'şehir', 'şekil', 'şimdi', 'işte', 'şöyle', 'tabiat', 'toprak', 'vatan', 'aydın', 'yukarı', 'yalnız', 'yeni', 'yarar', 'yavaş', 'yüzyıl', 'özel', 'uzun', 'üzere']\n",
      "158.41379310344828\n",
      "225.64592307027345\n",
      "        word  count   z_score  log_count  z_score_log z_categories  percentage\n",
      "51    yukarı     64 -0.418416   4.174387    -0.013379   orta düşük    0.464374\n",
      "52    devlet     61 -0.431711   4.127134    -0.044417   orta düşük    0.442606\n",
      "53     şöyle     58 -0.445006   4.077537    -0.076995   orta düşük    0.420839\n",
      "54     soğuk     56 -0.453869   4.043051    -0.099647   orta düşük    0.406327\n",
      "55     lazım     55 -0.458301   4.025352    -0.111273   orta düşük    0.399071\n",
      "56     sıcak     46 -0.498187   3.850148    -0.226356   orta düşük    0.333769\n",
      "57    bundan     44 -0.507050   3.806662    -0.254920   orta düşük    0.319257\n",
      "58    yüzyıl     41 -0.520345   3.737670    -0.300238   orta düşük    0.297489\n",
      "59      çoğu     38 -0.533640   3.663562    -0.348916   orta düşük    0.275722\n",
      "60  kahraman     37 -0.538072   3.637586    -0.365978   orta düşük    0.268466\n",
      "61      bazı     36 -0.542504   3.610918    -0.383495   orta düşük    0.261210\n",
      "62    kuvvet     34 -0.551367   3.555348    -0.419996   orta düşük    0.246699\n",
      "63     şekil     33 -0.555799   3.526361    -0.439037   orta düşük    0.239443\n"
     ]
    }
   ],
   "source": [
    "# İki Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# İki harfli kısaltmalar listesi\n",
    "csv_path_cons_double = 'data/contractions/cons_double.csv'\n",
    "df_cons_double = pd.read_csv(csv_path_cons_double, header=None)\n",
    "# 2. sütundaki değerleri listeye al\n",
    "contractions_double = df_cons_double[1].tolist()\n",
    "print(contractions_double)\n",
    "\n",
    "# 1) Listedeki her sözcükle BAŞLAYAN tüm sözcüklerin toplam frekansını bulalım\n",
    "results = []\n",
    "for cword in contractions_double:\n",
    "    sub_count = df[df['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "    # Eğer sözcüklerin yumuşamış formları varsa frekansa ekle\n",
    "    if cword == \"çocuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"çocuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"kitap\":\n",
    "        sub_count += df[df['word'].str.startswith(\"kitab\", na=False)]['count'].sum()\n",
    "    elif cword == \"küçük\":\n",
    "        sub_count += df[df['word'].str.startswith(\"küçüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"sıcak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"sıcağ\", na=False)]['count'].sum()\n",
    "    elif cword == \"soğuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"soğuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"toprak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"toprağ\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_double_freq = pd.DataFrame(results)\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_double = df_double_freq['count'].mean()\n",
    "std_val_double = df_double_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_double == 0:\n",
    "    df_double_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekleyelim\n",
    "\n",
    "    df_double_freq['z_score'] = (df_double_freq['count'] - mean_val_double) / std_val_double\n",
    "\n",
    "# 4) Log-Transfer uygula\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_double_freq['log_count'] = np.log1p(df_double_freq['count'])  # log(count + 1)\n",
    "\n",
    "# 5) Log değerlerin ortalamasını ve std'sini alın\n",
    "mean_double_log = df_double_freq['log_count'].mean()\n",
    "std_double_log = df_double_freq['log_count'].std()\n",
    "\n",
    "# 6) Log değer üzerinden z-skoru\n",
    "if std_double_log == 0:\n",
    "    df_double_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_double_freq['z_score_log'] = (df_double_freq['log_count'] - mean_double_log) / std_double_log\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları (soldan sağa sıralı):\n",
    "bins = [-np.inf, -1, -0.5, 0, 0.5, 1, np.inf]\n",
    "# Bu aralıklara denk gelen etiketler (labels):\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta düşük\", \"orta yüksek\", \"yüksek\", \"çok yüksek\"]\n",
    "df_double_freq['z_categories'] = pd.cut(df_double_freq['z_score_log'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_double = df_double_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_double_freq['percentage'] = (df_double_freq['count'] / total_count_double) * 100\n",
    "df_double_percent = df_double_freq[['word', 'count', 'percentage', 'z_score_log', 'z_categories']]\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_double_percent = df_double_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(mean_val_double)\n",
    "print(std_val_double)\n",
    "print(df_double_percent)\n",
    "# Çok düşük olanları sırala\n",
    "print(df_double_percent[df_double_percent['z_categories'] == 'orta düşük'])\n",
    "#print(df_double_percent[df_double_percent['word'] == 'küçük'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
