{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\Documents\\Python Projects\\tangible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set the path as tangible\n",
    "os.chdir('..')\n",
    "\n",
    "# Check current path \n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 102-Ahmet Ümit _ İstanbul Hatırası\n"
     ]
    }
   ],
   "source": [
    "# Read the text file\n",
    "file_path = 'data/contractions/102-Ahmet Ümit _ İstanbul Hatırası.txt'\n",
    "base_name = os.path.basename(file_path)\n",
    "document_name = os.path.splitext(base_name)[0]\n",
    "print(\"Document: \" + document_name)\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Küçük harfe dönüştür\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 2) Noktalama işaretlerini sil (regex ile)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#    Burada ^\\w\\s -> Alfanumerik karakterler ve boşluklar dışındaki her şeyi temizleyecek.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Küçük harfe dönüştür\n",
    "text = text.lower()\n",
    "\n",
    "# 2) Noktalama işaretlerini sil (regex ile)\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# 3) Sayı vb. temizle\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Tokenization\n",
    "tokens = text.split()  # Boşluk karakterine göre ayırır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create data frame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtokens\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Gruplayarak frekans (count) değerini hesapla\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# Create data frame\n",
    "df = pd.DataFrame(tokens, columns=['word'])\n",
    "df['count'] = 1\n",
    "\n",
    "# Gruplayarak frekans (count) değerini hesapla\n",
    "word_counts = df.groupby('word')['count'].sum().reset_index()\n",
    "# Dosya ismini ekle\n",
    "word_counts['source'] = document_name\n",
    "\n",
    "# Frekansına göre büyükten küçüğe sırala\n",
    "word_counts = word_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# İlk 20 kelimeyi görüntüleyelim\n",
    "print(word_counts.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasına kaydet\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    # CSV yoksa oluştur (header dahil)\n",
    "    word_counts.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "else:\n",
    "    # CSV varsa oku ve birleştir (append)\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    combined_df = pd.concat([existing_df, word_counts], ignore_index=True)\n",
    "    combined_df.to_csv(csv_path, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.870993819594753\n",
      "43.793707573021614\n",
      "                    word  count     z_score\n",
      "4821                 bir   5659  129.108251\n",
      "5356                  bu   2932   66.839032\n",
      "31948                 ve   2425   55.262026\n",
      "7022                  de   2004   45.648773\n",
      "6669                  da   1519   34.574122\n",
      "...                  ...    ...         ...\n",
      "38324      şüphelenmemiş      1   -0.088392\n",
      "38323  şüpheleniyorsunuz      1   -0.088392\n",
      "38322  şüpheleniyorsanız      1   -0.088392\n",
      "38321            şüpheci      1   -0.088392\n",
      "15                 abdye      1   -0.088392\n",
      "\n",
      "[38347 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Tekrar eden sözcükleri birleştir\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sözcük bazında topla\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "df_merged = df_merged.sort_values('count', ascending=False)\n",
    "\n",
    "# Eğer 'source' (belge adı) sütunu da varsa ve hem 'word' hem de 'source' bazında birleştirmek istiyorsanız:\n",
    "# df_merged = df.groupby(['word', 'source'], as_index=False)['count'].sum()\n",
    "# Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val = df_merged['count'].mean()\n",
    "std_val = df_merged['count'].std()\n",
    "\n",
    "# Standart sapmanın 0 olması ihtimaline karşı kontrol et\n",
    "if std_val == 0:\n",
    "    # Böyle bir durumda tüm z-skorları 0 yapılabilir\n",
    "    df_merged['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekle\n",
    "    df_merged['z_score'] = (df_merged['count'] - mean_val) / std_val\n",
    "\n",
    "# Sonucu incele\n",
    "print(mean_val)\n",
    "print(std_val)\n",
    "print(df_merged)\n",
    "\n",
    "# CSV olarak kaydet\n",
    "#df_merged.to_csv('data/contractions/word_frequencies_merged.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "4.4000730441134275\n",
      "21.36408305210143\n",
      "     word  count    z_score\n",
      "0     ama   1335  62.282099\n",
      "1      ne   1234  57.554538\n",
      "2    için   1053  49.082375\n",
      "3    daha    970  45.197349\n",
      "4   kadar    751  34.946500\n",
      "5    diye    738  34.338002\n",
      "6     çok    601  27.925370\n",
      "7     her    573  26.614759\n",
      "8   sonra    556  25.819031\n",
      "9      en    503  23.338232\n",
      "10  değil    498  23.104194\n",
      "11    ben    497  23.057387\n",
      "12  bütün    494  22.916964\n",
      "13    iki    489  22.682927\n",
      "14     mi    485  22.495696\n",
      "15    hiç    473  21.934006\n",
      "16   bile    441  20.436165\n",
      "17   önce    437  20.248935\n",
      "18  büyük    421  19.500014\n",
      "19    ali    421  19.500014\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "import nltk\n",
    "\n",
    "# Türkçe stopword'leri indirelim (bir kereye mahsus)\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK'nin Türkçe stopword'lerini alalım (tamamen yeterli olmayabilir, isteğe göre genişletilebilir)\n",
    "#turkish_stopwords_nltk = stopwords.words('turkish')\n",
    "turkish_stopwords_nltk = []\n",
    "print(turkish_stopwords_nltk)\n",
    "# Ek olarak kendi özel stopword listenizi de tanımlayabilirsiniz\n",
    "csv_path_stopwords = 'data/contractions/stopwords.csv'\n",
    "df_my_stopwords = pd.read_csv(csv_path_stopwords, header=None)\n",
    "my_stopwords = df_my_stopwords[0].tolist()\n",
    "# İki listeyi birleştirelim\n",
    "\n",
    "turkish_stopwords = set(turkish_stopwords_nltk + my_stopwords)\n",
    "\n",
    "# --- Asıl analiz ---\n",
    "\n",
    "# 1) CSV'yi okuyalım\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Sözcük bazında topla (aynı 'word' birden çok satırda olabilir diye)\n",
    "df_merged = df.groupby('word', as_index=False)['count'].sum()\n",
    "\n",
    "# 3) Stopword’leri çıkaralım\n",
    "df_stopwords_removed = df_merged[~df_merged['word'].isin(turkish_stopwords)]\n",
    "\n",
    "# 4) Temizlenmiş veriyi frekansa göre sırala\n",
    "df_stopwords_removed = df_stopwords_removed.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "#df_stopwords_removed = df_stopwords_removed.sort_values('word', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 5) Ortalamayı ve standart sapmayı hesaplayalım\n",
    "mean_val_sw = df_stopwords_removed['count'].mean()\n",
    "std_val_sw = df_stopwords_removed['count'].std()\n",
    "\n",
    "# 6) Z-skorunu hesapla\n",
    "if std_val_sw == 0:\n",
    "    df_stopwords_removed['z_score'] = 0\n",
    "else:\n",
    "    df_stopwords_removed['z_score'] = (df_stopwords_removed['count'] - mean_val_sw) / std_val_sw\n",
    "\n",
    "# 7) Sonucu görelim\n",
    "print(mean_val_sw)\n",
    "print(std_val_sw)\n",
    "print(df_stopwords_removed.head(20))\n",
    "\n",
    "# 8) İsterseniz CSV olarak kaydedebilirsiniz\n",
    "# df_stopwords_removed.to_csv('data/contractions/word_frequencies_merged_no_stopwords.csv', \n",
    "#                             index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [word, count, source]\n",
      "Index: []\n",
      "402.42857142857144\n",
      "286.86122965532496\n",
      "       word  count  percentage  z_score_log z_categories\n",
      "0      daha    976    8.661697     0.975982       yüksek\n",
      "1       var    945    8.386581     0.953657       yüksek\n",
      "2     kadar    797    7.073127     0.835857       yüksek\n",
      "3       her    765    6.789137     0.807520       yüksek\n",
      "4       yok    736    6.531771     0.780797       yüksek\n",
      "5       çok    637    5.653177     0.680920       yüksek\n",
      "6       gün    617    5.475683     0.658867       yüksek\n",
      "7       şey    613    5.440185     0.654371       yüksek\n",
      "8     sonra    609    5.404686     0.649846       yüksek\n",
      "9     zaman    554    4.916578     0.584421       yüksek\n",
      "10     için    543    4.818956     0.570560       yüksek\n",
      "11    büyük    469    4.162229     0.469321  orta yüksek\n",
      "12     öyle    379    3.363507     0.322145  orta yüksek\n",
      "13    artık    349    3.097267     0.265204  orta yüksek\n",
      "14     göre    331    2.937522     0.228646  orta yüksek\n",
      "15     ilgi    277    2.458289     0.105737  orta yüksek\n",
      "16    neden    262    2.325169     0.067332  orta yüksek\n",
      "17    fakat    243    2.156550     0.015412  orta yüksek\n",
      "18    dünya    236    2.094427    -0.004742   orta düşük\n",
      "19     aynı    232    2.058928    -0.016528   orta düşük\n",
      "20      can    211    1.872559    -0.081926   orta düşük\n",
      "21     para    162    1.437700    -0.263912   orta düşük\n",
      "22    taraf    149    1.322329    -0.321460   orta düşük\n",
      "23     kısa     80    0.709975    -0.748103        düşük\n",
      "24   meydan     72    0.638978    -0.820105        düşük\n",
      "25    uygun     17    0.150870    -1.789516    çok düşük\n",
      "26     eğer      5    0.044373    -2.550187    çok düşük\n",
      "27  ekonomi      2    0.017749    -3.030118    çok düşük\n"
     ]
    }
   ],
   "source": [
    "# Bir Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df_single = pd.read_csv(csv_path)\n",
    "\n",
    "# Tek harfli kısaltmalar listesi\n",
    "csv_path_con_single = 'data/contractions/con_single.csv'\n",
    "df_con_single = pd.read_csv(csv_path_con_single, header=None)\n",
    "contractions_list_single = df_con_single[0].tolist()\n",
    "\n",
    "# Stopwordleri çıkar\n",
    "csv_path_stopwords_single = 'data/contractions/stopwords_single.csv'\n",
    "df_my_stopwords_single = pd.read_csv(csv_path_stopwords_single, header=None)\n",
    "my_stopwords_single = df_my_stopwords_single[0].tolist()\n",
    "df_single = df_single[~df_single['word'].isin(my_stopwords_single)]\n",
    "#print(df_single[df_single['word'] == 'gibi'])\n",
    "\n",
    "# 1) Listedeki sözcüklerle BAŞLAYAN tüm sözcüklerin toplam frekansını hesapla\n",
    "results = []\n",
    "for cword in contractions_list_single:\n",
    "    sub_count = df_single[df_single['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "\n",
    "    # Eğer 'büyük' ve 'artık' sözcüklerinin yumuşamış formları varsa frekansa ekle\n",
    "    if cword == \"büyük\":\n",
    "        sub_count += df_single[df_single['word'].str.startswith(\"büyüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"artık\":\n",
    "        sub_count += df_single[df_single['word'].str.startswith(\"artığ\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_single_freq = pd.DataFrame(results)\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_single = df_single_freq['count'].mean()\n",
    "std_val_single = df_single_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_single == 0:\n",
    "    # Böyle bir durumda tüm z-skorlarını 0 yap\n",
    "    df_single_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekleyelim\n",
    "    df_single_freq['z_score'] = (df_single_freq['count'] - mean_val_single) / std_val_single\n",
    "\n",
    "# 4) Log-Transfer uygula\n",
    "\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_single_freq['log_count'] = np.log1p(df_single_freq['count'])  # log(count + 1)\n",
    "\n",
    "# 5) Log değerlerin ortalamasını ve std'sini alın\n",
    "mean_log = df_single_freq['log_count'].mean()\n",
    "std_log = df_single_freq['log_count'].std()\n",
    "\n",
    "# 6) Log değer üzerinden z-skoru\n",
    "if std_log == 0:\n",
    "    df_single_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_single_freq['z_score_log'] = (df_single_freq['log_count'] - mean_log) / std_log\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları (soldan sağa sıralı):\n",
    "bins = [-np.inf, -1, -0.5, 0, 0.5, 1, np.inf]\n",
    "# Bu aralıklara denk gelen etiketler (labels):\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta düşük\", \"orta yüksek\", \"yüksek\", \"çok yüksek\"]\n",
    "df_single_freq['z_categories'] = pd.cut(df_single_freq['z_score_log'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_single = df_single_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_single_freq['percentage'] = (df_single_freq['count'] / total_count_single) * 100\n",
    "df_single_percent = df_single_freq[['word', 'count', 'percentage', 'z_score_log', 'z_categories']]\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_single_percent = df_single_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(mean_val_single)\n",
    "print(std_val_single)\n",
    "print(df_single_percent)\n",
    "# Çok düşük olanları sırala\n",
    "#print(df_single_freq[df_single_freq['z_categories'] == 'yüksek'])\n",
    "#print(df_single_percent[df_single_percent['word'] == 'büyük'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beden', 'bağımsız', 'bilgi', 'bundan', 'beraber', 'basit', 'başka', 'bütün', 'böyle', 'bazı', 'cumhuriyet', 'cisim', 'cevap', 'çocuk', 'çoğu', 'çalışkan', 'çünkü', 'çeşit', 'çevre', 'değil', 'dolayı', 'demek', 'deney', 'devlet', 'fazla', 'gibi', 'gece', 'genel', 'güzel', 'haber', 'hiç', 'halk', 'hemen', 'hangi', 'hepsi', 'hayat', 'hazır', 'kabul', 'küçük', 'kadın', 'kahraman', 'kolay', 'kendi', 'kısım', 'kitap', 'kuvvet', 'kuzey', 'lazım', 'madde', 'millet', 'memleket', 'ancak', 'niçin', 'anadolu', 'nehir', 'anne', 'insan', 'arka', 'örneğin', 'arası', 'orta', 'sebep', 'sıcak', 'soğuk', 'eski', 'osmanlı', 'soru', 'savaş', 'aşağı', 'şehir', 'şekil', 'şimdi', 'işte', 'şöyle', 'tabiat', 'toprak', 'vatan', 'aydın', 'yukarı', 'yalnız', 'yeni', 'yarar', 'yavaş', 'yüzyıl', 'özel', 'uzun', 'üzere']\n",
      "158.41379310344828\n",
      "225.64592307027345\n",
      "        word  count  percentage  z_score_log z_categories\n",
      "71     kuzey     13    0.094326    -1.021864    çok düşük\n",
      "72   beraber     12    0.087070    -1.070542    çok düşük\n",
      "73     basit     12    0.087070    -1.070542    çok düşük\n",
      "74  memleket     12    0.087070    -1.070542    çok düşük\n",
      "75     niçin     11    0.079814    -1.123118    çok düşük\n",
      "76     madde      9    0.065303    -1.242876    çok düşük\n",
      "77   örneğin      8    0.058047    -1.312083    çok düşük\n",
      "78     sebep      8    0.058047    -1.312083    çok düşük\n",
      "79     nehir      6    0.043535    -1.477159    çok düşük\n",
      "80     cevap      6    0.043535    -1.477159    çok düşük\n",
      "81  bağımsız      4    0.029023    -1.698172    çok düşük\n",
      "82   anadolu      4    0.029023    -1.698172    çok düşük\n",
      "83  çalışkan      3    0.021768    -1.844744    çok düşük\n",
      "84     kısım      1    0.007256    -2.300039    çok düşük\n",
      "85     cisim      0    0.000000    -2.755335    çok düşük\n",
      "86    tabiat      0    0.000000    -2.755335    çok düşük\n"
     ]
    }
   ],
   "source": [
    "# İki Harfli Kısaltmalar: Z-Skoru\n",
    "\n",
    "# CSV'yi oku\n",
    "csv_path = 'data/contractions/word_frequencies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# İki harfli kısaltmalar listesi\n",
    "csv_path_cons_double = 'data/contractions/cons_double.csv'\n",
    "df_cons_double = pd.read_csv(csv_path_cons_double, header=None)\n",
    "# 2. sütundaki değerleri listeye al\n",
    "contractions_double = df_cons_double[1].tolist()\n",
    "print(contractions_double)\n",
    "\n",
    "# 1) Listedeki her sözcükle BAŞLAYAN tüm sözcüklerin toplam frekansını bulalım\n",
    "results = []\n",
    "for cword in contractions_double:\n",
    "    sub_count = df[df['word'].str.startswith(cword, na=False)]['count'].sum()\n",
    "    # Eğer sözcüklerin yumuşamış formları varsa frekansa ekle\n",
    "    if cword == \"çocuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"çocuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"kitap\":\n",
    "        sub_count += df[df['word'].str.startswith(\"kitab\", na=False)]['count'].sum()\n",
    "    elif cword == \"küçük\":\n",
    "        sub_count += df[df['word'].str.startswith(\"küçüğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"sıcak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"sıcağ\", na=False)]['count'].sum()\n",
    "    elif cword == \"soğuk\":\n",
    "        sub_count += df[df['word'].str.startswith(\"soğuğ\", na=False)]['count'].sum()\n",
    "    elif cword == \"toprak\":\n",
    "        sub_count += df[df['word'].str.startswith(\"toprağ\", na=False)]['count'].sum()\n",
    "\n",
    "    results.append({'word': cword, 'count': sub_count})\n",
    "\n",
    "df_double_freq = pd.DataFrame(results)\n",
    "\n",
    "# 2) Ortalamayı ve standart sapmayı hesapla\n",
    "mean_val_double = df_double_freq['count'].mean()\n",
    "std_val_double = df_double_freq['count'].std()\n",
    "\n",
    "# 3) Standart sapmanın 0 olması ihtimaline karşı kontrol yap\n",
    "if std_val_double == 0:\n",
    "    df_double_freq['z_score'] = 0\n",
    "else:\n",
    "    # (count - ortalama) / std formülüyle z-skorunu ekleyelim\n",
    "\n",
    "    df_double_freq['z_score'] = (df_double_freq['count'] - mean_val_double) / std_val_double\n",
    "\n",
    "# 4) Log-Transfer uygula\n",
    "# 'count' değerleri için log(1+x) dönüşümü\n",
    "df_double_freq['log_count'] = np.log1p(df_double_freq['count'])  # log(count + 1)\n",
    "\n",
    "# 5) Log değerlerin ortalamasını ve std'sini alın\n",
    "mean_double_log = df_double_freq['log_count'].mean()\n",
    "std_double_log = df_double_freq['log_count'].std()\n",
    "\n",
    "# 6) Log değer üzerinden z-skoru\n",
    "if std_double_log == 0:\n",
    "    df_double_freq['z_score_log'] = 0\n",
    "else:\n",
    "    df_double_freq['z_score_log'] = (df_double_freq['log_count'] - mean_double_log) / std_double_log\n",
    "\n",
    "# 7) Z-Skoruna göre kategorilere ayır\n",
    "# Kategoriler için bin aralıkları (soldan sağa sıralı):\n",
    "bins = [-np.inf, -1, -0.5, 0, 0.5, 1, np.inf]\n",
    "# Bu aralıklara denk gelen etiketler (labels):\n",
    "labels = [\"çok düşük\", \"düşük\", \"orta düşük\", \"orta yüksek\", \"yüksek\", \"çok yüksek\"]\n",
    "df_double_freq['z_categories'] = pd.cut(df_double_freq['z_score_log'], bins=bins, labels=labels)\n",
    "\n",
    "# 8) Yüzdelik hesapla\n",
    "# Toplam 'count' değerini hesapla\n",
    "total_count_double = df_double_freq['count'].sum()\n",
    "# Yeni sütun: 'percentage' (yüzde)\n",
    "df_double_freq['percentage'] = (df_double_freq['count'] / total_count_double) * 100\n",
    "df_double_percent = df_double_freq[['word', 'count', 'percentage', 'z_score_log', 'z_categories']]\n",
    "\n",
    "\n",
    "# 9) Sırala ve sonucu yazdır\n",
    "df_double_percent = df_double_percent.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(mean_val_double)\n",
    "print(std_val_double)\n",
    "#print(df_double_percent)\n",
    "# Çok düşük olanları sırala\n",
    "print(df_double_percent[df_double_percent['z_categories'] == 'çok düşük'])\n",
    "#print(df_double_percent[df_double_percent['word'] == 'küçük'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
