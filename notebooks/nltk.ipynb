{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Python Projects\\tangible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK stopword listesini indir (eÄŸer daha Ã¶nce indirilmemiÅŸse)\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Set the path as tangible\n",
    "os.chdir('..')\n",
    "\n",
    "# Check current path \n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: article_1977_1\n",
      "<class 'list'>\n",
      "\n",
      "ðŸ”¹ Quadrigram FrekanslarÄ±:\n",
      "                                    Quadrigram  Frekans\n",
      "1256         (Ã¶zel, eÄŸitime, muhtaÃ§, Ã§ocuklar)        5\n",
      "4350  (kendi, ÅŸartlarÄ±mÄ±za, gÃ¶re, hazÄ±rlanmÄ±ÅŸ)        5\n",
      "4354   (geÃ§erli, gÃ¼venilir, zekÃ¢, testlerinde)        5\n",
      "4355   (gÃ¼venilir, zekÃ¢, testlerinde, devamlÄ±)        5\n",
      "4356      (zekÃ¢, testlerinde, devamlÄ±, olarak)        5\n",
      "...                                        ...      ...\n",
      "7959            (dil, kurumu, yayÄ±nlarÄ±, Ã¶zel)        1\n",
      "7960         (kurumu, yayÄ±nlarÄ±, Ã¶zel, eÄŸitim)        1\n",
      "7961         (yayÄ±nlarÄ±, Ã¶zel, eÄŸitim, bÃ¶lÃ¼mÃ¼)        1\n",
      "7962           (Ã¶zel, eÄŸitim, bÃ¶lÃ¼mÃ¼, Ã¶ÄŸretim)        1\n",
      "9       (terimlerin, Ã§okluÄŸu, tÃ¼rkiyede, Ã¶zel)        1\n",
      "\n",
      "[7964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the text file\n",
    "file_path = 'data/ankara_oe/article_1977_1.txt'\n",
    "base_name = os.path.basename(file_path)\n",
    "document_name = os.path.splitext(base_name)[0]\n",
    "print(\"Document: \" + document_name)\n",
    "\n",
    "# Metin dosyasÄ±\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "#stop_words = set(stopwords.words('turkish'))\n",
    "custom_stopwords = set([\n",
    "    \"ama\", \"bir\", \"bu\", \"Ã§ok\", \"daha\", \"gibi\", \"iÃ§in\", \"ile\", \"ise\", \"Ã¶nemli\",  \"ÅŸu\", \"ve\"\n",
    "])\n",
    "\n",
    "# Metni kÃ¼Ã§Ã¼k harfe Ã§evirme ve temizleme\n",
    "text = text.lower()\n",
    "text = re.sub(r'[^\\w\\s]', '', text)  # Noktalama iÅŸaretlerini kaldÄ±r\n",
    "\n",
    "# Kelimeleri tokenize et ve stopwordâ€™leri kaldÄ±r\n",
    "tokens = [word for word in text.split() if word not in custom_stopwords]\n",
    "\n",
    "# Unigram, bigram ve trigramlarÄ± oluÅŸtur\n",
    "unigrams = tokens\n",
    "#print(type(unigrams))\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "quadrigram = list(ngrams(tokens, 4))\n",
    "\n",
    "# FrekanslarÄ± hesapla\n",
    "unigram_freq = Counter(unigrams)\n",
    "bigram_freq = Counter(bigrams)\n",
    "trigram_freq = Counter(trigrams)\n",
    "quadrigram_freq = Counter(quadrigram)\n",
    "\n",
    "# En sÄ±k geÃ§enleri seÃ§\n",
    "#top_unigrams = unigram_freq.most_common(10)\n",
    "top_bigrams = bigram_freq.most_common(10)\n",
    "top_trigrams = trigram_freq.most_common(10)\n",
    "top_quadrigrams = quadrigram_freq.most_common(10)\n",
    "\n",
    "# SonuÃ§larÄ± DataFrame olarak hazÄ±rlama\n",
    "df_unigram = pd.DataFrame(unigram_freq.items(), columns=[\"Unigram\", \"Frekans\"]).sort_values(by=\"Frekans\", ascending=False)\n",
    "\n",
    "df_bigram = pd.DataFrame([\" \".join(bigram) for bigram, freq in top_bigrams], columns=[\"Bigram\"])\n",
    "df_bigram[\"Frekans\"] = [freq for bigram, freq in top_bigrams]\n",
    "\n",
    "df_trigram = pd.DataFrame([\" \".join(trigram) for trigram, freq in top_trigrams], columns=[\"Trigram\"])\n",
    "df_trigram[\"Frekans\"] = [freq for trigram, freq in top_trigrams]\n",
    "\n",
    "df_quadrigram = pd.DataFrame(quadrigram_freq.items(), columns=[\"Quadrigram\", \"Frekans\"]).sort_values(by=\"Frekans\", ascending=False)\n",
    "\n",
    "# UnigramlarÄ± GÃ¶rÃ¼ntÃ¼le\n",
    "#print(\"\\nðŸ”¹ Unigram FrekanslarÄ±:\")\n",
    "#print(df_unigram)\n",
    "\n",
    "# BigramlarÄ± GÃ¶rÃ¼ntÃ¼le\n",
    "#print(\"\\nðŸ”¹ Bigram FrekanslarÄ±:\")\n",
    "#print(df_bigram)\n",
    "\n",
    "# **TrigramlarÄ± GÃ¶rÃ¼ntÃ¼le**\n",
    "#print(\"\\nðŸ”¹ Trigram FrekanslarÄ±:\")\n",
    "#print(df_trigram)\n",
    "\n",
    "# QuadrigramlarÄ± GÃ¶rÃ¼ntÃ¼le\n",
    "print(\"\\nðŸ”¹ Quadrigram FrekanslarÄ±:\")\n",
    "print(df_quadrigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24786, 2)\n",
      "                                  Terim  TF-IDF Skoru\n",
      "0                                   bir      0.753827\n",
      "1                                 kadar      0.100176\n",
      "2                                 sonra      0.095168\n",
      "3                                   ben      0.082646\n",
      "4                                eÄŸitim      0.082646\n",
      "...                                 ...           ...\n",
      "24749                           ÅŸiÅŸenin      0.002504\n",
      "24750               ÅŸiÅŸenin serinliÄŸini      0.002504\n",
      "24751  ÅŸiÅŸenin serinliÄŸini hissediyorum      0.002504\n",
      "24752                            ÅŸiÅŸeyi      0.002504\n",
      "21687                       yazabiliyor      0.002504\n",
      "\n",
      "[24786 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=list(stop_words))\n",
    "tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "# Kelimelerin Ã¶nem sÄ±rasÄ±na gÃ¶re alÄ±nmasÄ±\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "scores = tfidf_matrix.toarray().flatten()\n",
    "\n",
    "# En Ã¶nemli kelimeleri sÄ±ralama\n",
    "important_terms = sorted(zip(feature_names, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Tablo olarak gÃ¶sterme\n",
    "df_tfidf = pd.DataFrame(important_terms, columns=[\"Terim\", \"TF-IDF Skoru\"])\n",
    "df_tfidf = df_tfidf.sort_values(by=\"TF-IDF Skoru\", ascending=False)\n",
    "print(df_tfidf.shape)\n",
    "print(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ FiltrelenmiÅŸ Terimlerin FrekanslarÄ±:\n",
      "                         Terim  Frekans\n",
      "0                         Ã¶zel       29\n",
      "1                  Ã¶zel eÄŸitim       20\n",
      "2            Ã¶zel eÄŸitim Ã§ocuk       16\n",
      "3                        bazen       15\n",
      "4                        biraz        6\n",
      "...                        ...      ...\n",
      "1160  ÅŸiirler yazmaya baÅŸladÄ±m        1\n",
      "1161                 ÅŸti kazÄ±m        1\n",
      "1162       ÅŸti kazÄ±m karabekir        1\n",
      "1163              ÅŸunlarÄ± Ã¶zel        1\n",
      "1164       ÅŸunlarÄ± Ã¶zel eÄŸitim        1\n",
      "\n",
      "[1165 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Anahtar SÃ¶zcÃ¼kler\n",
    "keywords = [\n",
    "    \"az\",\n",
    "    \"bÃ¼tÃ¼nleÅŸtirme\"\n",
    "    \"gÃ¶rme\",\n",
    "    \"kaynaÅŸtÄ±rma\",\n",
    "    \"otizm\",\n",
    "    \"Ã¶zel\",\n",
    "    \"yetersizli\",\n",
    "    \"zihin\"\n",
    "]\n",
    "\n",
    "# **Ã–nemli terimleri filtreleme (TF-IDF sonucundan)**\n",
    "filtered_terms = [term for term, score in important_terms if any(keyword in term for keyword in keywords)]\n",
    "\n",
    "# **Sonucu DataFrame olarak saklama**\n",
    "df_filtered = pd.DataFrame(filtered_terms, columns=[\"Ã–zel EÄŸitim Terimleri\"])\n",
    "\n",
    "# **FrekanslarÄ± hesaplama (unigram, bigram, trigram iÃ§inde arama)**\n",
    "filtered_frequencies = {}\n",
    "\n",
    "for term in df_filtered[\"Ã–zel EÄŸitim Terimleri\"]:\n",
    "    # Unigram frekansÄ±\n",
    "    unigram_count = unigram_freq.get(term, 0)\n",
    "    # Bigram frekansÄ±\n",
    "    bigram_count = bigram_freq.get(tuple(term.split()), 0)\n",
    "    # Trigram frekansÄ±\n",
    "    trigram_count = trigram_freq.get(tuple(term.split()), 0)\n",
    "\n",
    "    # Toplam frekans\n",
    "    total_count = unigram_count + bigram_count + trigram_count\n",
    "    filtered_frequencies[term] = total_count\n",
    "\n",
    "# **Yeni DataFrame oluÅŸtur (terimler ve frekanslarÄ±)**\n",
    "df_final = pd.DataFrame(filtered_frequencies.items(), columns=[\"Terim\", \"Frekans\"])\n",
    "\n",
    "# **Sonucu gÃ¶sterme**\n",
    "print(\"\\nðŸ”¹ FiltrelenmiÅŸ Terimlerin FrekanslarÄ±:\")\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Ã–zel EÄŸitim Terimlerinin FrekanslarÄ±:\n",
      "                         Terim  Frekans          Source\n",
      "29                        Ã¶zÃ¼r       75  article_1977_1\n",
      "23                 Ã¶zel eÄŸitim       71  article_1977_1\n",
      "33                       saÄŸÄ±r       58  article_1977_1\n",
      "18                         kÃ¶r       56  article_1977_1\n",
      "38                 geri zekÃ¢lÄ±       42  article_1977_1\n",
      "34                       sakat       34  article_1977_1\n",
      "0                        arÄ±za       34  article_1977_1\n",
      "30                      Ã¶zÃ¼rlÃ¼       20  article_1977_1\n",
      "1                      arÄ±zalÄ±       10  article_1977_1\n",
      "35                 yetersizlik        8  article_1977_1\n",
      "36           yetersizliÄŸi olan        7  article_1977_1\n",
      "28         Ã¶zel eÄŸitime muhtaÃ§        7  article_1977_1\n",
      "32              rehabilitasyon        6  article_1977_1\n",
      "2                     az gÃ¶ren        5  article_1977_1\n",
      "20                       otizm        4  article_1977_1\n",
      "24          Ã¶zel eÄŸitim hizmet        4  article_1977_1\n",
      "15                gÃ¶rme Ã¶zÃ¼rlÃ¼        4  article_1977_1\n",
      "39                 geri zekalÄ±        4  article_1977_1\n",
      "19                         Ã¢mÃ¢        3  article_1977_1\n",
      "27  Ã¶zel eÄŸitime ihtiyacÄ± olan        2  article_1977_1\n",
      "31           birden fazla Ã¶zÃ¼r        1  article_1977_1\n",
      "3                     bireysel        1  article_1977_1\n",
      "(22, 3)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Analiz edilecek Ã¶zel eÄŸitim terimleri\n",
    "special_ed_terms = [\n",
    "    \"arÄ±za\", \"arÄ±zalÄ±\",\n",
    "    \"az gÃ¶ren\",\n",
    "    \"bireysel\", \"bireysel farklÄ±lÄ±k\", \"bireyselleÅŸtirme\", \"bireyselleÅŸtirilmiÅŸ\",\n",
    "    \"bireyselleÅŸtirilmiÅŸ eÄŸitim\", \"bireysel eÄŸitim\",\n",
    "    \"bireyselleÅŸtirilmiÅŸ eÄŸitim programÄ±\", \"bireyselleÅŸtirilmiÅŸ eÄŸitim planÄ±\",\n",
    "    \"destek eÄŸitim\",\n",
    "    \"disleksi\",\n",
    "    \"gÃ¶rme engeli\", \"gÃ¶rme engelli\", \"gÃ¶rme Ã¶zÃ¼rlÃ¼\", \"gÃ¶rme yetersizliÄŸi\", \"gÃ¶rme yetersizliÄŸi olan\",\n",
    "    \"kÃ¶r\", \"Ã¢mÃ¢\",\n",
    "    \"otizm\", \"otistik\", \"otizm spektrum bozukluÄŸu\",\n",
    "    \"Ã¶zel eÄŸitim\",\n",
    "    \"Ã¶zel eÄŸitim hizmet\",\n",
    "    \"Ã¶zel gereksinim\", \"Ã¶zel gereksinimli\", \"Ã¶zel eÄŸitime ihtiyacÄ± olan\", \"Ã¶zel eÄŸitime muhtaÃ§\",\n",
    "    \"Ã¶zÃ¼r\", \"Ã¶zÃ¼rlÃ¼\", \"birden fazla Ã¶zÃ¼r\",\n",
    "    \"rehabilitasyon\",\n",
    "    \"saÄŸÄ±r\",\n",
    "    \"sakat\",\n",
    "    \"yetersizlik\", \"yetersizliÄŸi olan\",\n",
    "    \"zeka geriliÄŸi\", \"geri zekÃ¢lÄ±\", \"geri zekalÄ±\",\n",
    "    \"zihin yetersizliÄŸi\", \"zihinsel yetersizlik\", \"zihinsel yetersizliÄŸi olan\"\n",
    "]\n",
    "\n",
    "# ðŸ”¹ Terimlerin frekanslarÄ±nÄ± hesaplama\n",
    "term_frequencies = {}\n",
    "\n",
    "for term in special_ed_terms:\n",
    "    term_words = term.split()  # Terimi kelimelerine ayÄ±r\n",
    "    term_length = len(term_words)  # KaÃ§ kelimeden oluÅŸtuÄŸunu Ã¶ÄŸren\n",
    "    matched_positions = set()  # **Tekrar sayÄ±lmasÄ±nÄ± Ã¶nlemek iÃ§in bir set kullanÄ±yoruz**\n",
    "\n",
    "    # ðŸ”¹ EÄŸer terim tek kelimeden oluÅŸuyorsa, baÅŸÄ±nda geÃ§tiÄŸi kelimeleri tarayalÄ±m\n",
    "    if term_length == 1:\n",
    "        base_word = term_words[0]  # Tek kelime\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].startswith(base_word):  # **BaÅŸlangÄ±Ã§ta geÃ§iyor mu?**\n",
    "                matched_positions.add(i)\n",
    "\n",
    "    # ðŸ”¹ EÄŸer terim birden fazla kelime iÃ§eriyorsa, son kelimenin baÅŸÄ±na eklenmiÅŸ halleri tarayalÄ±m\n",
    "    else:\n",
    "        base_word = term_words[-1]  # **Son kelimeyi al**\n",
    "        for i in range(len(tokens) - term_length + 1):\n",
    "            if tokens[i:i + term_length - 1] == term_words[:-1] and tokens[i + term_length - 1].startswith(base_word):\n",
    "                matched_positions.add(i)\n",
    "\n",
    "    # **FrekansÄ± kaydet**\n",
    "    term_frequencies[term] = len(matched_positions)\n",
    "\n",
    "# **SonuÃ§larÄ± DataFrame olarak kaydet**\n",
    "df_special_terms = pd.DataFrame(term_frequencies.items(), columns=[\"Terim\", \"Frekans\"]).sort_values(by=\"Frekans\", ascending=False)\n",
    "df_special_terms['Source'] = document_name\n",
    "\n",
    "# **SonuÃ§larÄ± gÃ¶sterme**\n",
    "print(\"\\nðŸ”¹ Ã–zel EÄŸitim Terimlerinin FrekanslarÄ±:\")\n",
    "print(df_special_terms[df_special_terms[\"Frekans\"] > 0])\n",
    "print(df_special_terms[df_special_terms[\"Frekans\"] > 0].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
